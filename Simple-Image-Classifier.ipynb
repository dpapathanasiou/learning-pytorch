{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Image Classifier\n",
    "\n",
    "Implementing Chapter 2 of [Programming PyTorch for Deep Learning](http://shop.oreilly.com/product/0636920216032.do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "This is a simple three layer network: an input and hidden layer, with a two-node output layer.\n",
    "\n",
    "It is *fully-connected* in that each node in each layer affects every node the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.input_layer = nn.Linear(12288, 84)\n",
    "        self.hidden_layer = nn.Linear(84, 50)\n",
    "        self.output_layer = nn.Linear(50, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 12288)\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        x = F.relu(self.hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(simple.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, training_loader, validation_loader, epochs, device=\"cpu\"):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        validation_loss = 0.0\n",
    "        model.train()\n",
    "        for (inputs, targets) in training_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item()\n",
    "        training_loss /= len(training_loader)\n",
    "        \n",
    "        number_correct = 0\n",
    "        number_examples = 0\n",
    "        model.eval()\n",
    "        for (inputs, targets) in validation_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            validation_loss += loss.data.item()\n",
    "            correct = torch.eq(torch.max(F.softmax(outputs, dim=1), dim=1)[1], targets).view(-1)\n",
    "            number_correct += torch.sum(correct).item()\n",
    "            number_examples += correct.shape[0]\n",
    "        validation_loss /= len(validation_loader)\n",
    "        \n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(\n",
    "            epoch, \n",
    "            training_loss,\n",
    "            validation_loss, \n",
    "            number_correct / number_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Using the [technique from lesson 2](https://github.com/dpapathanasiou/course-v3/blob/master/nbs/dl1/lesson2-download.ipynb) of the [Fast.ai course](https://course.fast.ai/), get a list of image urls with some in-browser javascript:\n",
    "\n",
    "```javascript\n",
    "urls=Array.from(document.querySelectorAll('.rg_i')).map(el=> el.hasAttribute('data-src')?el.getAttribute('data-src'):el.getAttribute('data-iurl'));window.open('data:text/csv;charset=utf-8,' + escape(urls.join('\\n')));\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "def fetch_images(image_url_list, target):\n",
    "    data_file = Path(image_url_list)\n",
    "    for i, url in enumerate(data_file.read_text().splitlines()):\n",
    "        image_file = Path(target) / str(i) # TODO: determine file extension, since ImageFolders needs it\n",
    "        urllib.request.urlretrieve(url, image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of `cat` versus `fish`, this notebook will attempt [aikido](https://en.wikipedia.org/wiki/Aikido) verus [judo](https://en.wikipedia.org/wiki/Judo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_images(\"./data/aikido_train.csv\", \"./data/train/aikido\")\n",
    "fetch_images(\"./data/aikido_validate.csv\", \"./data/validate/aikido\")\n",
    "fetch_images(\"./data/aikido_test.csv\", \"./data/test/aikido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_images(\"./data/judo_train.csv\", \"./data/train/judo\")\n",
    "fetch_images(\"./data/judo_validate.csv\", \"./data/validate/judo\")\n",
    "fetch_images(\"./data/judo_test.csv\", \"./data/test/judo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose(\n",
    "    [transforms.Resize((64,64)), \n",
    "     transforms.ToTensor(),    \n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],                    \n",
    "                          std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data   = torchvision.datasets.ImageFolder(root=\"./data/train\",    transform=image_transform)\n",
    "validation_data = torchvision.datasets.ImageFolder(root=\"./data/validate\", transform=image_transform)\n",
    "test_data       = torchvision.datasets.ImageFolder(root=\"./data/test\",     transform=image_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "training_loader   = DataLoader(training_data, batch_size=batch_size)\n",
    "validation_loader = DataLoader(validation_data, batch_size=batch_size)\n",
    "test_loader       = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.31, Validation Loss: 0.36, accuracy = 0.82\n",
      "Epoch: 1, Training Loss: 0.26, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 2, Training Loss: 0.18, Validation Loss: 0.34, accuracy = 0.82\n",
      "Epoch: 3, Training Loss: 0.11, Validation Loss: 0.34, accuracy = 0.82\n",
      "Epoch: 4, Training Loss: 0.08, Validation Loss: 0.34, accuracy = 0.82\n",
      "Epoch: 5, Training Loss: 0.06, Validation Loss: 0.34, accuracy = 0.82\n",
      "Epoch: 6, Training Loss: 0.05, Validation Loss: 0.34, accuracy = 0.82\n",
      "Epoch: 7, Training Loss: 0.04, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 8, Training Loss: 0.03, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 9, Training Loss: 0.03, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 10, Training Loss: 0.02, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 11, Training Loss: 0.02, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 12, Training Loss: 0.02, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 13, Training Loss: 0.02, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 14, Training Loss: 0.02, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 15, Training Loss: 0.01, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 16, Training Loss: 0.01, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 17, Training Loss: 0.01, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 18, Training Loss: 0.01, Validation Loss: 0.34, accuracy = 0.80\n",
      "Epoch: 19, Training Loss: 0.01, Validation Loss: 0.35, accuracy = 0.80\n"
     ]
    }
   ],
   "source": [
    "train(simple, optimizer, torch.nn.CrossEntropyLoss(), training_loader, validation_loader, 20, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "How does the model do against the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device=\"cpu\"):\n",
    "    i = 0\n",
    "    for (inputs, targets) in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        correct = torch.eq(torch.max(F.softmax(outputs, dim=1), dim=1)[1], targets)\n",
    "        right = len(list(filter(lambda x: x.item(), list(correct))))\n",
    "        wrong = batch_size - right\n",
    "        print('Batch {}: {} right vs {} wrong (pct correct {:.2f})'.format(i, right, wrong, (right / batch_size)))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: 8 right vs 2 wrong (pct correct 0.80)\n",
      "Batch 1: 9 right vs 1 wrong (pct correct 0.90)\n",
      "Batch 2: 5 right vs 5 wrong (pct correct 0.50)\n",
      "Batch 3: 7 right vs 3 wrong (pct correct 0.70)\n"
     ]
    }
   ],
   "source": [
    "test(simple, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addendum: discovering the optimal learning rate\n",
    "\n",
    "Chapter 4 covers `Transfer Learning` and explains a technique for finding the optimal learning rate based on [this paper](https://arxiv.org/abs/1506.01186)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def find_lr(model, optimizer, loss_fn, train_loader, device, init_value=1e-8, final_value=10.0):\n",
    "    number_in_epoch = len(train_loader) - 1\n",
    "    update_step = (final_value / init_value) ** (1 / number_in_epoch)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0][\"lr\"] = lr\n",
    "    best_loss = 0.0\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    for data in train_loader:\n",
    "        batch_num += 1\n",
    "        inputs, targets = data\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # Crash out if loss explodes\n",
    "        if batch_num > 1 and loss > 4 * best_loss:\n",
    "            if(len(log_lrs) > 20):\n",
    "                return log_lrs[10:-5], losses[10:-5]\n",
    "            else:\n",
    "                return log_lrs, losses\n",
    "\n",
    "        # Record the best loss\n",
    "        if loss < best_loss or batch_num == 1:\n",
    "            best_loss = loss\n",
    "\n",
    "        # Store the values\n",
    "        losses.append(loss.item())\n",
    "        log_lrs.append((lr))\n",
    "\n",
    "        # Do the backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the lr for the next step and store\n",
    "        lr *= update_step\n",
    "        optimizer.param_groups[0][\"lr\"] = lr\n",
    "        \n",
    "    if(len(log_lrs) > 20):\n",
    "        return log_lrs[10:-5], losses[10:-5]\n",
    "    else:\n",
    "        return log_lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs, losses = find_lr(simple, optimizer, nn.CrossEntropyLoss(), training_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(logs, losses)\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1e-08,\n",
       "  1.93069772888325e-07,\n",
       "  3.7275937203149393e-06,\n",
       "  7.196856730011518e-05,\n",
       "  0.001389495494373137,\n",
       "  0.026826957952797242,\n",
       "  0.5179474679231207],\n",
       " [0.6722691655158997,\n",
       "  0.7030429840087891,\n",
       "  0.6768912672996521,\n",
       "  0.6772599816322327,\n",
       "  0.7393165230751038,\n",
       "  1.324784755706787,\n",
       "  8.046303264563903e-06])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using this found rate in training\n",
    "simple2 = SimpleNN()\n",
    "found_lr = 7.196856730011518e-05\n",
    "optimizer2 = optim.Adam(simple2.parameters(), lr=found_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.68, Validation Loss: 0.49, accuracy = 0.80\n",
      "Epoch: 1, Training Loss: 0.40, Validation Loss: 0.40, accuracy = 0.80\n",
      "Epoch: 2, Training Loss: 0.31, Validation Loss: 0.39, accuracy = 0.80\n",
      "Epoch: 3, Training Loss: 0.23, Validation Loss: 0.38, accuracy = 0.80\n",
      "Epoch: 4, Training Loss: 0.18, Validation Loss: 0.37, accuracy = 0.80\n",
      "Epoch: 5, Training Loss: 0.13, Validation Loss: 0.37, accuracy = 0.80\n",
      "Epoch: 6, Training Loss: 0.11, Validation Loss: 0.36, accuracy = 0.82\n",
      "Epoch: 7, Training Loss: 0.08, Validation Loss: 0.36, accuracy = 0.82\n",
      "Epoch: 8, Training Loss: 0.07, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 9, Training Loss: 0.06, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 10, Training Loss: 0.05, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 11, Training Loss: 0.04, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 12, Training Loss: 0.04, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 13, Training Loss: 0.03, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 14, Training Loss: 0.03, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 15, Training Loss: 0.03, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 16, Training Loss: 0.02, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 17, Training Loss: 0.02, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 18, Training Loss: 0.02, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 19, Training Loss: 0.02, Validation Loss: 0.37, accuracy = 0.85\n"
     ]
    }
   ],
   "source": [
    "train(simple2, optimizer2, torch.nn.CrossEntropyLoss(), training_loader, validation_loader, 20, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: 7 right vs 3 wrong (pct correct 0.70)\n",
      "Batch 1: 8 right vs 2 wrong (pct correct 0.80)\n",
      "Batch 2: 6 right vs 4 wrong (pct correct 0.60)\n",
      "Batch 3: 8 right vs 2 wrong (pct correct 0.80)\n"
     ]
    }
   ],
   "source": [
    "test(simple2, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
