{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Image Classifier\n",
    "\n",
    "Implementing Chapter 2 of [Programming PyTorch for Deep Learning](http://shop.oreilly.com/product/0636920216032.do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "This is a simple three layer network: an input and hidden layer, with a two-node output layer.\n",
    "\n",
    "It is *fully-connected* in that each node in each layer affects every node the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.input_layer = nn.Linear(12288, 84)\n",
    "        self.hidden_layer = nn.Linear(84, 50)\n",
    "        self.output_layer = nn.Linear(50, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 12288)\n",
    "        x = F.Relu(self.input_layer(x))\n",
    "        x = F.Relu(self.hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(simple.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, training_loader, validation_loader, epochs, device=\"cpu\"):\n",
    "    for epoch in xrange(epochs):\n",
    "        training_loss = 0.0\n",
    "        validation_loss = 0.0\n",
    "        model.train()\n",
    "        for (inputs, targets) in training_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item()\n",
    "        training_loss /= len(training_loader)\n",
    "        \n",
    "        number_correct = 0\n",
    "        number_examples = 0\n",
    "        model.eval()\n",
    "        for (inputs, targets) in validation_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            validation_loss += loss.data.item()\n",
    "            correct = torch.eq(torch.max(F.softmax(outputs), dim=1)[1], targets).view(-1)\n",
    "            number_correct += torch.sum(correct).item()\n",
    "            number_examples += correct.shape[0]\n",
    "        validation_loss /= len(validation_loader)\n",
    "        \n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(\n",
    "            epoch, \n",
    "            training_loss,\n",
    "            validation_loss, \n",
    "            number_correct / num_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Using the [technique from lesson 2](https://github.com/dpapathanasiou/course-v3/blob/master/nbs/dl1/lesson2-download.ipynb) of the [Fast.ai course](https://course.fast.ai/), get a list of image urls with some in-browser javascript:\n",
    "\n",
    "```javascript\n",
    "urls=Array.from(document.querySelectorAll('.rg_i')).map(el=> el.hasAttribute('data-src')?el.getAttribute('data-src'):el.getAttribute('data-iurl'));window.open('data:text/csv;charset=utf-8,' + escape(urls.join('\\n')));\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "def fetch_images(image_url_list, target):\n",
    "    data_file = Path(image_url_list)\n",
    "    for i, url in enumerate(data_file.read_text().splitlines()):\n",
    "        image_file = Path(target) / str(i) # TODO: determine file extension, since ImageFolders needs it\n",
    "        urllib.request.urlretrieve(url, image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of `cat` versus `fish`, this notebook will attempt [aikido](https://en.wikipedia.org/wiki/Aikido) verus [judo](https://en.wikipedia.org/wiki/Judo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_images(\"./data/aikido_train.csv\", \"./data/train/aikido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_images(\"./data/aikido_validate.csv\", \"./data/validate/aikido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_images(\"./data/aikido_test.csv\", \"./data/test/aikido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_images(\"./data/judo_train.csv\", \"./data/train/judo\")\n",
    "fetch_images(\"./data/judo_validate.csv\", \"./data/validate/judo\")\n",
    "fetch_images(\"./data/judo_test.csv\", \"./data/test/judo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose(\n",
    "    [transforms.Resize(64), \n",
    "     transforms.ToTensor(),    \n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],                    \n",
    "                          std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data   = torchvision.datasets.ImageFolder(root=\"./data/train\",    transform=image_transform)\n",
    "validation_data = torchvision.datasets.ImageFolder(root=\"./data/validate\", transform=image_transform)\n",
    "test_data       = torchvision.datasets.ImageFolder(root=\"./data/test\",     transform=image_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "training_loader   = DataLoader(training_data, batch_size=batch_size)\n",
    "validation_loader = DataLoader(validation_data, batch_size=batch_size)\n",
    "test_loader       = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, optimizer, loss_fn, training_loader, validation_loader, epochs, device=\"cpu\"):\n",
    "train(simple, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, test_data_loader, 20, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
