{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classifier\n",
    "\n",
    "Chapter 5 of Programming PyTorch for Deep Learning, but using samples from the [TREC 2005 Spam Corpus](https://trec.nist.gov/data/spam.html) instead of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext import data \n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenize(s):\n",
    "    return s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=my_tokenize)\n",
    "LABEL = data.Field(lower=True)\n",
    "samples = data.TabularDataset(path='./data/ham-spam-samples.tsv',\n",
    "                              format='tsv', \n",
    "                              fields=[(\"label\",LABEL), (\"statement\",TEXT)],\n",
    "                              skip_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 60, 60)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(training, testing, validating) = samples.split(split_ratio=[0.6,0.2,0.2])\n",
    "(len(training),len(testing),len(validating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1569),\n",
       " ('to', 1027),\n",
       " ('of', 847),\n",
       " ('and', 820),\n",
       " ('>', 618),\n",
       " ('in', 528),\n",
       " ('a', 459),\n",
       " ('this', 439),\n",
       " ('for', 387),\n",
       " ('is', 379)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 30000\n",
    "TEXT.build_vocab(training, max_size = vocab_size)\n",
    "LABEL.build_vocab(training)\n",
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7607"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ['ham'],\n",
       " 'statement': ['per',\n",
       "  'eric',\n",
       "  'moon',\n",
       "  '-',\n",
       "  'attached',\n",
       "  'you',\n",
       "  'will',\n",
       "  'find',\n",
       "  'the',\n",
       "  'structuring',\n",
       "  'slide',\n",
       "  'for',\n",
       "  'citibank',\n",
       "  'prepay,',\n",
       "  'with',\n",
       "  'the',\n",
       "  'changes.',\n",
       "  'melissa',\n",
       "  'solis',\n",
       "  'enron',\n",
       "  'north',\n",
       "  'america',\n",
       "  'melissa.solis@enron.com',\n",
       "  'w:',\n",
       "  '713-853-5167',\n",
       "  'f:',\n",
       "  '713-646-3460']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(training.examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "(training, validating, testing), \n",
    "batch_size = 32,\n",
    "device = device,\n",
    "sort_key = lambda x: len(x.statement),\n",
    "sort_within_batch = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model\n",
    "\n",
    "Start with a simple [Long short-term memory (LSTM)](https://en.wikipedia.org/wiki/Long_short-term_memory) model. \n",
    "\n",
    "Unlike the book, which relies on a three-part classifier, this model is doing a binary comparison, with an activation ([sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function)) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_dim, vocab_size):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=1)\n",
    "        self.predictor = nn.Linear(hidden_size, 1)\n",
    "        self.activator = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, seq):\n",
    "        output, (hidden, _) = self.encoder(self.embedding(seq))\n",
    "        prediction = self.predictor(torch.squeeze(hidden))\n",
    "        prediction = self.activator(prediction)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'dataset': <torchtext.data.dataset.Dataset at 0x7fd466925ad0>,\n",
       " 'fields': dict_keys(['label', 'statement']),\n",
       " 'input_fields': ['label', 'statement'],\n",
       " 'target_fields': [],\n",
       " 'label': tensor([[2, 2, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "          2, 3, 2, 2, 2, 2, 2, 2]]),\n",
       " 'statement': tensor([[5070,   30, 1193,  ...,  714,  910,  316],\n",
       "         [  13, 1119,  538,  ...,  714,   27, 2768],\n",
       "         [ 138,  137,  606,  ...,  143,   13, 6334],\n",
       "         ...,\n",
       "         [   1,    1,  375,  ...,    1,    1,    1],\n",
       "         [   1,    1,  541,  ...,    1,    1,    1],\n",
       "         [   1,    1,  580,  ...,    1,    1,    1]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_example = next(iter(train_iterator))\n",
    "vars(training_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicLSTM(\n",
       "  (embedding): Embedding(30000, 300)\n",
       "  (encoder): LSTM(300, 100)\n",
       "  (predictor): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (activator): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BasicLSTM(100, 300, 30000)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, nn, optimizer, criterion, train_iterator, valid_iterator):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        nn.train()\n",
    "        for batch_idx, batch in enumerate(train_iterator):\n",
    "            optimizer.zero_grad()\n",
    "            predict = nn(batch.statement)\n",
    "            loss = criterion(predict, batch.label.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * batch.statement.size(0)\n",
    "        training_loss /= len(train_iterator)\n",
    " \n",
    "        \n",
    "        model.eval()\n",
    "        for batch_idx,batch in enumerate(valid_iterator):\n",
    "            predict = model(batch.statement)\n",
    "            loss = criterion(predict, batch.label.float())\n",
    "            valid_loss += loss.data.item() * batch.statement.size(0)\n",
    " \n",
    "        valid_loss /= len(valid_iterator)\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}'.format(epoch, training_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([1, 32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/denis/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([1, 21])) that is different to the input size (torch.Size([21, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/denis/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([1, 28])) that is different to the input size (torch.Size([28, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: -1362.23, Validation Loss: -2794.45\n",
      "Epoch: 2, Training Loss: -4558.47, Validation Loss: -4524.70\n",
      "Epoch: 3, Training Loss: -6600.54, Validation Loss: -5774.53\n",
      "Epoch: 4, Training Loss: -8401.95, Validation Loss: -6795.56\n",
      "Epoch: 5, Training Loss: -9089.07, Validation Loss: -7634.39\n"
     ]
    }
   ],
   "source": [
    "train(5, model, optimizer, criterion, train_iterator, valid_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    categories = {0: 'ham', 1: 'spam'}\n",
    "    processed = TEXT.process([TEXT.preprocess(text)])\n",
    "    processed = processed.to(device)\n",
    "    return categories[model(processed).argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_text(testing.examples[0].statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.examples[0].label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct   --> 1/1 right overall 100.00%\n",
      "Correct   --> 2/2 right overall 100.00%\n",
      "Correct   --> 3/3 right overall 100.00%\n",
      "Incorrect --> 3/4 right overall 75.00%\n",
      "Correct   --> 4/5 right overall 80.00%\n",
      "Correct   --> 5/6 right overall 83.33%\n",
      "Incorrect --> 5/7 right overall 71.43%\n",
      "Incorrect --> 5/8 right overall 62.50%\n",
      "Incorrect --> 5/9 right overall 55.56%\n",
      "Correct   --> 6/10 right overall 60.00%\n",
      "Correct   --> 7/11 right overall 63.64%\n",
      "Incorrect --> 7/12 right overall 58.33%\n",
      "Correct   --> 8/13 right overall 61.54%\n",
      "Incorrect --> 8/14 right overall 57.14%\n",
      "Correct   --> 9/15 right overall 60.00%\n",
      "Incorrect --> 9/16 right overall 56.25%\n",
      "Correct   --> 10/17 right overall 58.82%\n",
      "Incorrect --> 10/18 right overall 55.56%\n",
      "Correct   --> 11/19 right overall 57.89%\n",
      "Incorrect --> 11/20 right overall 55.00%\n",
      "Incorrect --> 11/21 right overall 52.38%\n",
      "Correct   --> 12/22 right overall 54.55%\n",
      "Correct   --> 13/23 right overall 56.52%\n",
      "Correct   --> 14/24 right overall 58.33%\n",
      "Correct   --> 15/25 right overall 60.00%\n",
      "Incorrect --> 15/26 right overall 57.69%\n",
      "Correct   --> 16/27 right overall 59.26%\n",
      "Incorrect --> 16/28 right overall 57.14%\n",
      "Correct   --> 17/29 right overall 58.62%\n",
      "Correct   --> 18/30 right overall 60.00%\n",
      "Correct   --> 19/31 right overall 61.29%\n",
      "Correct   --> 20/32 right overall 62.50%\n",
      "Incorrect --> 20/33 right overall 60.61%\n",
      "Correct   --> 21/34 right overall 61.76%\n",
      "Correct   --> 22/35 right overall 62.86%\n",
      "Correct   --> 23/36 right overall 63.89%\n",
      "Incorrect --> 23/37 right overall 62.16%\n",
      "Correct   --> 24/38 right overall 63.16%\n",
      "Incorrect --> 24/39 right overall 61.54%\n",
      "Correct   --> 25/40 right overall 62.50%\n",
      "Incorrect --> 25/41 right overall 60.98%\n",
      "Correct   --> 26/42 right overall 61.90%\n",
      "Correct   --> 27/43 right overall 62.79%\n",
      "Incorrect --> 27/44 right overall 61.36%\n",
      "Incorrect --> 27/45 right overall 60.00%\n",
      "Correct   --> 28/46 right overall 60.87%\n",
      "Incorrect --> 28/47 right overall 59.57%\n",
      "Incorrect --> 28/48 right overall 58.33%\n",
      "Incorrect --> 28/49 right overall 57.14%\n",
      "Correct   --> 29/50 right overall 58.00%\n",
      "Correct   --> 30/51 right overall 58.82%\n",
      "Incorrect --> 30/52 right overall 57.69%\n",
      "Correct   --> 31/53 right overall 58.49%\n",
      "Correct   --> 32/54 right overall 59.26%\n",
      "Correct   --> 33/55 right overall 60.00%\n",
      "Correct   --> 34/56 right overall 60.71%\n",
      "Correct   --> 35/57 right overall 61.40%\n",
      "Correct   --> 36/58 right overall 62.07%\n",
      "Correct   --> 37/59 right overall 62.71%\n",
      "Correct   --> 38/60 right overall 63.33%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "examined = 0\n",
    "for test_example in testing.examples:\n",
    "    actual = test_example.label[0]\n",
    "    predicted = classify_text(test_example.statement)\n",
    "    examined += 1\n",
    "    if actual == predicted:\n",
    "        correct += 1\n",
    "        print('Correct   --> {}/{} right overall {:.2%}'.format(correct, examined, correct / examined))\n",
    "    else:\n",
    "        print('Incorrect --> {}/{} right overall {:.2%}'.format(correct, examined, correct / examined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
