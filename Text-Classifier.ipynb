{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classifier\n",
    "\n",
    "Chapter 5 of Programming PyTorch for Deep Learning, but using samples from the [TREC 2005 Spam Corpus](https://trec.nist.gov/data/spam.html) instead of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext import data \n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenize(s):\n",
    "    return s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=my_tokenize)\n",
    "LABEL = data.Field(lower=True)\n",
    "samples = data.TabularDataset(path='./data/ham-spam-samples.tsv',\n",
    "                              format='tsv', \n",
    "                              fields=[(\"label\",LABEL), (\"statement\",TEXT)],\n",
    "                              skip_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 80, 80)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(training, testing, validating) = samples.split(split_ratio=[0.6,0.2,0.2])\n",
    "(len(training),len(testing),len(validating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2001', 535),\n",
       " ('jul', 486),\n",
       " ('by', 345),\n",
       " ('with', 321),\n",
       " ('for', 275),\n",
       " ('from:', 272),\n",
       " ('id', 267),\n",
       " ('to:', 257),\n",
       " ('esmtp', 205),\n",
       " ('received:', 205)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 80\n",
    "TEXT.build_vocab(training, max_size = vocab_size)\n",
    "LABEL.build_vocab(training)\n",
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ['spam'],\n",
       " 'statement': ['by',\n",
       "  'mailman.enron.com',\n",
       "  '(8.10.1/8.10.1/corp-1.06)',\n",
       "  'with',\n",
       "  'esmtp',\n",
       "  'id',\n",
       "  'g343bbl02201',\n",
       "  'for',\n",
       "  '<plucci@enron.com>;',\n",
       "  'wed,',\n",
       "  '4',\n",
       "  'jul',\n",
       "  '2001',\n",
       "  '16:44:34',\n",
       "  '-0500',\n",
       "  '(cdt)',\n",
       "  'received:',\n",
       "  'from',\n",
       "  'by',\n",
       "  ';',\n",
       "  'wed,',\n",
       "  '4',\n",
       "  'jul',\n",
       "  '2001',\n",
       "  '23:44:20',\n",
       "  '+0200',\n",
       "  'message-id:',\n",
       "  '<wbmgvuszeysubfxztajwtsp@yahoo.com>',\n",
       "  'from:',\n",
       "  '\"������\"',\n",
       "  '<lsong9@korea.com',\n",
       "  '>',\n",
       "  'reply-to:',\n",
       "  '\"������\"',\n",
       "  '<lsong9@korea.com',\n",
       "  '>',\n",
       "  'to:',\n",
       "  'plucci@enron.com',\n",
       "  'subject:',\n",
       "  '�ڡڡڸ���',\n",
       "  '100����',\n",
       "  '��',\n",
       "  '����',\n",
       "  '������.�ڡڡ�',\n",
       "  'date:',\n",
       "  'wed,',\n",
       "  '4',\n",
       "  'jul',\n",
       "  '2001',\n",
       "  '22:43:20',\n",
       "  '+0100',\n",
       "  'x-mailer:',\n",
       "  'microsoft',\n",
       "  'outlook,',\n",
       "  'build',\n",
       "  '10.0.2627',\n",
       "  'mime-version:',\n",
       "  '1.0',\n",
       "  'content-type:',\n",
       "  'multipart/alternative;',\n",
       "  'boundary=\"--37678190364954245\"',\n",
       "  'x-priority:',\n",
       "  '3',\n",
       "  'x-msmail-priority:',\n",
       "  'normal',\n",
       "  '----37678190364954245',\n",
       "  'content-type:',\n",
       "  'text/html;',\n",
       "  'content-transfer-encoding:',\n",
       "  'base64',\n",
       "  'pgh0bww+dqogidxozwfkpg0kica8bwv0ysbodhrwlwvxdwl2psjdb250zw50lxr5cguiignv',\n",
       "  'bnrlbnq9inrlehqvahrtbdsgy2hhcnnldd1ldwmta3iipg0kicagi']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(training.examples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "(training, validating, testing), \n",
    "batch_size = 32,\n",
    "device = device,\n",
    "sort_key = lambda x: len(x.statement),\n",
    "sort_within_batch = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model\n",
    "\n",
    "Start with a simple [Long short-term memory (LSTM)](https://en.wikipedia.org/wiki/Long_short-term_memory) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_dim, vocab_size):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=1)\n",
    "        self.predictor = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        output, (hidden, _) = self.encoder(self.embedding(seq))\n",
    "        preds = self.predictor(hidden.squeeze(0))\n",
    "        return preds.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, optimizer, criterion, train_iterator, valid_iterator):\n",
    "    m = nn.Sigmoid()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch_idx, batch in enumerate(train_iterator):\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(batch.statement)\n",
    "            loss = criterion(m(predict), batch.label.double())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * batch.statement.size(0)\n",
    "        training_loss /= len(train_iterator)\n",
    " \n",
    "        model.eval()\n",
    "        for batch_idx,batch in enumerate(valid_iterator):\n",
    "            predict = model(batch.statement)\n",
    "            loss = criterion(m(predict), batch.label.double())\n",
    "            valid_loss += loss.data.item() * batch.statement.size(0)\n",
    " \n",
    "        valid_loss /= len(valid_iterator)\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}'.format(epoch, training_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicLSTM(\n",
       "  (embedding): Embedding(82, 300)\n",
       "  (encoder): LSTM(300, 100)\n",
       "  (predictor): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BasicLSTM(100, 300, 82)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=2e-2)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([1, 32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/denis/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([1, 16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: -1045.51, Validation Loss: -1769.66\n",
      "Epoch: 2, Training Loss: -2595.64, Validation Loss: -3168.24\n",
      "Epoch: 3, Training Loss: -4062.20, Validation Loss: -4542.89\n",
      "Epoch: 4, Training Loss: -5407.56, Validation Loss: -5436.11\n",
      "Epoch: 5, Training Loss: -5473.46, Validation Loss: -4290.29\n"
     ]
    }
   ],
   "source": [
    "train(5, model, optimizer, criterion, train_iterator, valid_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    categories = {0: 'ham', 1: 'spam'}\n",
    "    processed = TEXT.process([TEXT.preprocess(text)])\n",
    "    processed = processed.to(device)\n",
    "    return categories[model(processed).argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_text(testing.examples[0].statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.examples[0].label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct   --> 1/1 right overall\n",
      "Incorrect --> 1/2 right overall\n",
      "Incorrect --> 1/3 right overall\n",
      "Correct   --> 2/4 right overall\n",
      "Incorrect --> 2/5 right overall\n",
      "Incorrect --> 2/6 right overall\n",
      "Correct   --> 3/7 right overall\n",
      "Incorrect --> 3/8 right overall\n",
      "Incorrect --> 3/9 right overall\n",
      "Incorrect --> 3/10 right overall\n",
      "Correct   --> 4/11 right overall\n",
      "Incorrect --> 4/12 right overall\n",
      "Correct   --> 5/13 right overall\n",
      "Correct   --> 6/14 right overall\n",
      "Correct   --> 7/15 right overall\n",
      "Correct   --> 8/16 right overall\n",
      "Incorrect --> 8/17 right overall\n",
      "Correct   --> 9/18 right overall\n",
      "Correct   --> 10/19 right overall\n",
      "Incorrect --> 10/20 right overall\n",
      "Correct   --> 11/21 right overall\n",
      "Correct   --> 12/22 right overall\n",
      "Correct   --> 13/23 right overall\n",
      "Incorrect --> 13/24 right overall\n",
      "Correct   --> 14/25 right overall\n",
      "Correct   --> 15/26 right overall\n",
      "Correct   --> 16/27 right overall\n",
      "Correct   --> 17/28 right overall\n",
      "Correct   --> 18/29 right overall\n",
      "Incorrect --> 18/30 right overall\n",
      "Incorrect --> 18/31 right overall\n",
      "Incorrect --> 18/32 right overall\n",
      "Incorrect --> 18/33 right overall\n",
      "Incorrect --> 18/34 right overall\n",
      "Correct   --> 19/35 right overall\n",
      "Correct   --> 20/36 right overall\n",
      "Incorrect --> 20/37 right overall\n",
      "Correct   --> 21/38 right overall\n",
      "Incorrect --> 21/39 right overall\n",
      "Incorrect --> 21/40 right overall\n",
      "Correct   --> 22/41 right overall\n",
      "Incorrect --> 22/42 right overall\n",
      "Correct   --> 23/43 right overall\n",
      "Incorrect --> 23/44 right overall\n",
      "Correct   --> 24/45 right overall\n",
      "Incorrect --> 24/46 right overall\n",
      "Incorrect --> 24/47 right overall\n",
      "Incorrect --> 24/48 right overall\n",
      "Correct   --> 25/49 right overall\n",
      "Incorrect --> 25/50 right overall\n",
      "Correct   --> 26/51 right overall\n",
      "Incorrect --> 26/52 right overall\n",
      "Incorrect --> 26/53 right overall\n",
      "Incorrect --> 26/54 right overall\n",
      "Incorrect --> 26/55 right overall\n",
      "Incorrect --> 26/56 right overall\n",
      "Correct   --> 27/57 right overall\n",
      "Incorrect --> 27/58 right overall\n",
      "Incorrect --> 27/59 right overall\n",
      "Correct   --> 28/60 right overall\n",
      "Incorrect --> 28/61 right overall\n",
      "Correct   --> 29/62 right overall\n",
      "Correct   --> 30/63 right overall\n",
      "Correct   --> 31/64 right overall\n",
      "Correct   --> 32/65 right overall\n",
      "Correct   --> 33/66 right overall\n",
      "Correct   --> 34/67 right overall\n",
      "Correct   --> 35/68 right overall\n",
      "Incorrect --> 35/69 right overall\n",
      "Correct   --> 36/70 right overall\n",
      "Incorrect --> 36/71 right overall\n",
      "Correct   --> 37/72 right overall\n",
      "Incorrect --> 37/73 right overall\n",
      "Incorrect --> 37/74 right overall\n",
      "Correct   --> 38/75 right overall\n",
      "Correct   --> 39/76 right overall\n",
      "Incorrect --> 39/77 right overall\n",
      "Incorrect --> 39/78 right overall\n",
      "Correct   --> 40/79 right overall\n",
      "Correct   --> 41/80 right overall\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "examined = 0\n",
    "for test_example in testing.examples:\n",
    "    actual = test_example.label[0]\n",
    "    predicted = classify_text(test_example.statement)\n",
    "    examined += 1\n",
    "    if actual == predicted:\n",
    "        correct += 1\n",
    "        print('Correct   --> {}/{} right overall'.format(correct, examined))\n",
    "    else:\n",
    "        print('Incorrect --> {}/{} right overall'.format(correct, examined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
