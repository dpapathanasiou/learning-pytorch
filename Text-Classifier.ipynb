{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classifier\n",
    "\n",
    "Chapter 5 of Programming PyTorch for Deep Learning, but using samples from the [TREC 2005 Spam Corpus](https://trec.nist.gov/data/spam.html) instead of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext import data \n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenize(s):\n",
    "    return s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=my_tokenize)\n",
    "LABEL = data.Field(lower=True)\n",
    "samples = data.TabularDataset(path='./data/ham-spam-samples.tsv',\n",
    "                              format='tsv', \n",
    "                              fields=[(\"label\",LABEL), (\"statement\",TEXT)],\n",
    "                              skip_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 60, 60)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(training, testing, validating) = samples.split(split_ratio=[0.6,0.2,0.2])\n",
    "(len(training),len(testing),len(validating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 598),\n",
       " ('to', 413),\n",
       " ('and', 299),\n",
       " ('of', 278),\n",
       " ('a', 223),\n",
       " ('for', 213),\n",
       " ('in', 200),\n",
       " ('you', 175),\n",
       " ('is', 174),\n",
       " ('your', 170)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 30000\n",
    "TEXT.build_vocab(training, max_size = vocab_size)\n",
    "LABEL.build_vocab(training)\n",
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4619"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ['ham'],\n",
       " 'statement': ['rod-many',\n",
       "  'thanks',\n",
       "  'for',\n",
       "  'helping',\n",
       "  'me',\n",
       "  'out',\n",
       "  'with',\n",
       "  'sabic.',\n",
       "  'it',\n",
       "  'was',\n",
       "  'nice',\n",
       "  'to',\n",
       "  'host',\n",
       "  'them',\n",
       "  'on',\n",
       "  'my',\n",
       "  'turf',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'look',\n",
       "  'across',\n",
       "  'the',\n",
       "  'table',\n",
       "  'at',\n",
       "  'a',\n",
       "  'bunch',\n",
       "  'of',\n",
       "  'guys',\n",
       "  'in',\n",
       "  'dish',\n",
       "  'dashes.',\n",
       "  \"i've\",\n",
       "  'gotten',\n",
       "  'great',\n",
       "  'feedback',\n",
       "  'and',\n",
       "  \"we're\",\n",
       "  'a',\n",
       "  'step',\n",
       "  'closer',\n",
       "  'in',\n",
       "  'landing',\n",
       "  'them',\n",
       "  'as',\n",
       "  'a',\n",
       "  'partner.',\n",
       "  'thanks',\n",
       "  'again.',\n",
       "  'terry']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(training.examples[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "(training, validating, testing), \n",
    "batch_size = 32,\n",
    "device = device,\n",
    "sort_key = lambda x: len(x.statement),\n",
    "sort_within_batch = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model\n",
    "\n",
    "Start with a simple [Long short-term memory (LSTM)](https://en.wikipedia.org/wiki/Long_short-term_memory) model. \n",
    "\n",
    "Unlike the book, which relies on a three-part classifier, this model is doing a binary comparison, with an activation ([sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function)) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_dim, vocab_size):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=1)\n",
    "        self.predictor = nn.Linear(hidden_size, 1)\n",
    "        self.activator = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, seq):\n",
    "        output, (hidden, _) = self.encoder(self.embedding(seq))\n",
    "        prediction = self.predictor(torch.squeeze(hidden))\n",
    "        prediction = self.activator(prediction)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(iter(train_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 21,\n",
       " 'dataset': <torchtext.data.dataset.Dataset at 0x7f43f68881d0>,\n",
       " 'fields': dict_keys(['label', 'statement']),\n",
       " 'input_fields': ['label', 'statement'],\n",
       " 'target_fields': [],\n",
       " 'label': tensor([[3, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 2]]),\n",
       " 'statement': tensor([[ 188,  474,  559,  ...,  754,    2, 1506],\n",
       "         [ 178,   14,  203,  ..., 4073,  245,   77],\n",
       "         [ 183,  778,  241,  ..., 1879,  588,   14],\n",
       "         ...,\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicLSTM(\n",
       "  (embedding): Embedding(30000, 300)\n",
       "  (encoder): LSTM(300, 100)\n",
       "  (predictor): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (activator): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BasicLSTM(100, 300, 30000)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, nn, optimizer, criterion, train_iterator, valid_iterator):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        nn.train()\n",
    "        for batch_idx, batch in enumerate(train_iterator):\n",
    "            optimizer.zero_grad()\n",
    "            predict = nn(batch.statement)\n",
    "            loss = criterion(predict, batch.label.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * batch.statement.size(0)\n",
    "        training_loss /= len(train_iterator)\n",
    " \n",
    "        \n",
    "        model.eval()\n",
    "        for batch_idx,batch in enumerate(valid_iterator):\n",
    "            predict = model(batch.statement)\n",
    "            loss = criterion(predict, batch.label.float())\n",
    "            valid_loss += loss.data.item() * batch.statement.size(0)\n",
    " \n",
    "        valid_loss /= len(valid_iterator)\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}'.format(epoch, training_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: -6739.23, Validation Loss: -5026.87\n",
      "Epoch: 2, Training Loss: -6885.04, Validation Loss: -5026.87\n",
      "Epoch: 3, Training Loss: -6868.81, Validation Loss: -5026.87\n",
      "Epoch: 4, Training Loss: -6762.66, Validation Loss: -5026.87\n",
      "Epoch: 5, Training Loss: -6782.96, Validation Loss: -5026.87\n",
      "Epoch: 6, Training Loss: -6854.80, Validation Loss: -5026.87\n",
      "Epoch: 7, Training Loss: -6954.90, Validation Loss: -5026.87\n",
      "Epoch: 8, Training Loss: -6868.28, Validation Loss: -5026.87\n",
      "Epoch: 9, Training Loss: -6868.24, Validation Loss: -5026.87\n",
      "Epoch: 10, Training Loss: -6855.04, Validation Loss: -5026.87\n",
      "Epoch: 11, Training Loss: -6918.01, Validation Loss: -5026.87\n",
      "Epoch: 12, Training Loss: -6864.77, Validation Loss: -5026.87\n",
      "Epoch: 13, Training Loss: -6825.58, Validation Loss: -5026.87\n",
      "Epoch: 14, Training Loss: -6945.06, Validation Loss: -5026.87\n",
      "Epoch: 15, Training Loss: -6866.98, Validation Loss: -5026.87\n",
      "Epoch: 16, Training Loss: -6841.51, Validation Loss: -5026.87\n",
      "Epoch: 17, Training Loss: -6855.71, Validation Loss: -5026.87\n",
      "Epoch: 18, Training Loss: -6774.51, Validation Loss: -5026.87\n",
      "Epoch: 19, Training Loss: -6865.86, Validation Loss: -5026.87\n",
      "Epoch: 20, Training Loss: -6874.10, Validation Loss: -5026.87\n"
     ]
    }
   ],
   "source": [
    "train(20, model, optimizer, criterion, train_iterator, valid_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    categories = {0: 'ham', 1: 'spam'}\n",
    "    processed = TEXT.process([TEXT.preprocess(text)])\n",
    "    processed = processed.to(device)\n",
    "    return categories[model(processed).argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_text(testing.examples[0].statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.examples[0].label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect --> 0/1 right overall 0.00%\n",
      "Correct   --> 1/2 right overall 50.00%\n",
      "Correct   --> 2/3 right overall 66.67%\n",
      "Incorrect --> 2/4 right overall 50.00%\n",
      "Correct   --> 3/5 right overall 60.00%\n",
      "Correct   --> 4/6 right overall 66.67%\n",
      "Correct   --> 5/7 right overall 71.43%\n",
      "Correct   --> 6/8 right overall 75.00%\n",
      "Incorrect --> 6/9 right overall 66.67%\n",
      "Correct   --> 7/10 right overall 70.00%\n",
      "Incorrect --> 7/11 right overall 63.64%\n",
      "Incorrect --> 7/12 right overall 58.33%\n",
      "Incorrect --> 7/13 right overall 53.85%\n",
      "Correct   --> 8/14 right overall 57.14%\n",
      "Incorrect --> 8/15 right overall 53.33%\n",
      "Incorrect --> 8/16 right overall 50.00%\n",
      "Correct   --> 9/17 right overall 52.94%\n",
      "Correct   --> 10/18 right overall 55.56%\n",
      "Correct   --> 11/19 right overall 57.89%\n",
      "Correct   --> 12/20 right overall 60.00%\n",
      "Correct   --> 13/21 right overall 61.90%\n",
      "Incorrect --> 13/22 right overall 59.09%\n",
      "Correct   --> 14/23 right overall 60.87%\n",
      "Correct   --> 15/24 right overall 62.50%\n",
      "Correct   --> 16/25 right overall 64.00%\n",
      "Incorrect --> 16/26 right overall 61.54%\n",
      "Correct   --> 17/27 right overall 62.96%\n",
      "Correct   --> 18/28 right overall 64.29%\n",
      "Correct   --> 19/29 right overall 65.52%\n",
      "Incorrect --> 19/30 right overall 63.33%\n",
      "Correct   --> 20/31 right overall 64.52%\n",
      "Correct   --> 21/32 right overall 65.62%\n",
      "Incorrect --> 21/33 right overall 63.64%\n",
      "Incorrect --> 21/34 right overall 61.76%\n",
      "Correct   --> 22/35 right overall 62.86%\n",
      "Incorrect --> 22/36 right overall 61.11%\n",
      "Incorrect --> 22/37 right overall 59.46%\n",
      "Incorrect --> 22/38 right overall 57.89%\n",
      "Correct   --> 23/39 right overall 58.97%\n",
      "Correct   --> 24/40 right overall 60.00%\n",
      "Correct   --> 25/41 right overall 60.98%\n",
      "Correct   --> 26/42 right overall 61.90%\n",
      "Incorrect --> 26/43 right overall 60.47%\n",
      "Correct   --> 27/44 right overall 61.36%\n",
      "Correct   --> 28/45 right overall 62.22%\n",
      "Incorrect --> 28/46 right overall 60.87%\n",
      "Correct   --> 29/47 right overall 61.70%\n",
      "Correct   --> 30/48 right overall 62.50%\n",
      "Correct   --> 31/49 right overall 63.27%\n",
      "Incorrect --> 31/50 right overall 62.00%\n",
      "Incorrect --> 31/51 right overall 60.78%\n",
      "Incorrect --> 31/52 right overall 59.62%\n",
      "Incorrect --> 31/53 right overall 58.49%\n",
      "Correct   --> 32/54 right overall 59.26%\n",
      "Incorrect --> 32/55 right overall 58.18%\n",
      "Incorrect --> 32/56 right overall 57.14%\n",
      "Correct   --> 33/57 right overall 57.89%\n",
      "Correct   --> 34/58 right overall 58.62%\n",
      "Correct   --> 35/59 right overall 59.32%\n",
      "Correct   --> 36/60 right overall 60.00%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "examined = 0\n",
    "for test_example in testing.examples:\n",
    "    actual = test_example.label[0]\n",
    "    predicted = classify_text(test_example.statement)\n",
    "    examined += 1\n",
    "    if actual == predicted:\n",
    "        correct += 1\n",
    "        print('Correct   --> {}/{} right overall {:.2%}'.format(correct, examined, correct / examined))\n",
    "    else:\n",
    "        print('Incorrect --> {}/{} right overall {:.2%}'.format(correct, examined, correct / examined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
